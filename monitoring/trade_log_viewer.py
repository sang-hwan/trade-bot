# monitoring/trade_log_viewer.py
# ------------------------------------------------------------
# ë§¤ë§¤ ë¡œê·¸ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ (Streamlit)
# - ì‹¤ì‹œê°„ trades.jsonlì„ ìš°ì„  ì½ê³ , ì—†ìœ¼ë©´ trades.csvë¡œ í´ë°±
# - 1~10ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨(ìŠ¬ë¼ì´ë” ì¡°ì ˆ)
# ì‹¤í–‰ ì˜ˆ:
#   streamlit run monitoring/trade_log_viewer.py --server.port 8501
#   # ë˜ëŠ” runs ë£¨íŠ¸ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì§€ì •
#   RUNS_ROOT=/path/to/runs streamlit run monitoring/trade_log_viewer.py
# ------------------------------------------------------------
from __future__ import annotations

import json
import os
from pathlib import Path
from typing import Optional

import pandas as pd
import streamlit as st

# ì„ íƒ ëª¨ë“ˆ(ì—†ìœ¼ë©´ í´ë°±)
try:
    from streamlit_autorefresh import st_autorefresh  # type: ignore
except Exception:
    st_autorefresh = None  # type: ignore


def _list_run_sessions(runs_root: Path) -> list[Path]:
    """runs/* í•˜ìœ„ ì„¸ì…˜ ë””ë ‰í„°ë¦¬ë¥¼ ìµœì‹  ìˆ˜ì •ìˆœìœ¼ë¡œ ë°˜í™˜."""
    if not runs_root.exists():
        return []
    items = [p for p in runs_root.iterdir() if p.is_dir()]
    items.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return items


def _read_jsonl(path: Path, limit: Optional[int] = None) -> list[dict]:
    """JSON Lines íŒŒì¼ì—ì„œ ìµœê·¼ limití–‰ê¹Œì§€ ì½ì–´ ë¦¬ìŠ¤íŠ¸[dict] ë°˜í™˜."""
    rows: list[dict] = []
    if not path or not path.exists():
        return rows
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            s = line.strip()
            if not s:
                continue
            try:
                rows.append(json.loads(s))
            except json.JSONDecodeError:
                # ì‹¤ì‹œê°„ append ì¤‘ ì†ìƒëœ ë¼ì¸ì€ ê±´ë„ˆëœ€
                continue
    if limit is not None and len(rows) > limit:
        rows = rows[-limit:]
    return rows


def _find_file(base: Path, name: str) -> Optional[Path]:
    """
    ê´€ìš© ê²½ë¡œ ìš°ì„ ìˆœìœ„ë¡œ íŒŒì¼ íƒìƒ‰:
      1) base/name
      2) base/outputs/name
      3) base/logs/name
    """
    for cand in (base / name, base / "outputs" / name, base / "logs" / name):
        if cand.exists():
            return cand
    return None


def _coalesce(*vals):
    """ì•ì—ì„œë¶€í„° Noneì´ ì•„ë‹Œ ì²« ê°’ì„ ë°˜í™˜."""
    for v in vals:
        if v is not None:
            return v
    return None


def _to_local_ts(ts: str, tz: str = "Asia/Seoul") -> str:
    """UTC ë¬¸ìì—´ì„ ë¡œì»¬í‘œì‹œ(YYYY-mm-dd HH:MM:SS)ë¡œ ë³€í™˜. ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜."""
    try:
        s = pd.to_datetime(ts, utc=True)
        s = s.tz_convert(tz)
        return s.strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return ts


# -------------------------- í˜ì´ì§€ ì„¤ì • --------------------------
st.set_page_config(page_title="Trade Log Viewer", layout="wide")
st.sidebar.title("âš™ï¸ ì„¤ì •")

# runs ë£¨íŠ¸: ê¸°ë³¸ ./runs, í™˜ê²½ë³€ìˆ˜ RUNS_ROOT ìš°ì„ (ì—†ìœ¼ë©´ ìƒì„±)
runs_root = Path(os.environ.get("RUNS_ROOT", "./runs")).expanduser().resolve()
runs_root.mkdir(parents=True, exist_ok=True)

# ì„¸ì…˜ ì„ íƒ: ì¿¼ë¦¬ìŠ¤íŠ¸ë§ ?session=... ìš°ì„ 
qs = st.query_params
qs_session = qs.get("session")
session_qs = qs_session if isinstance(qs_session, str) else None

sessions = _list_run_sessions(runs_root)
session_labels = [p.name for p in sessions]
default_idx = 0
if session_qs and session_qs in session_labels:
    default_idx = session_labels.index(session_qs)

sel_session = st.sidebar.selectbox(
    "ì„¸ì…˜ ì„ íƒ (runs/*)",
    session_labels or ["<ì„¸ì…˜ ì—†ìŒ>"],
    index=default_idx if session_labels else 0,
)
session_dir = runs_root / sel_session if session_labels else None

refresh_ms = st.sidebar.slider("ìë™ ìƒˆë¡œê³ ì¹¨ (ms)", 1000, 10000, 3000, 500)
max_rows = st.sidebar.slider("í‘œì‹œí•  ìµœëŒ€ í–‰ ìˆ˜", 50, 5000, 500, 50)
st.sidebar.caption("í™˜ê²½ë³€ìˆ˜ RUNS_ROOT ë¡œ runs ë£¨íŠ¸ ê²½ë¡œ ì§€ì • ê°€ëŠ¥")

# ìë™ ìƒˆë¡œê³ ì¹¨ (ì„ íƒ ëª¨ë“ˆ ì¡´ì¬ ì‹œ)
if st_autorefresh:
    st_autorefresh(interval=refresh_ms, key="trade_log_auto_refresh")

# -------------------------- ë³¸ë¬¸ --------------------------
st.title("ğŸ§¾ Trade Log Viewer")

if not session_dir or not session_dir.exists():
    st.warning("runs/* ì„¸ì…˜ í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. RUNS_ROOT ë˜ëŠ” ì„¸ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# -------------------------- ì…ë ¥ ì†ŒìŠ¤ ì„ íƒ --------------------------
# 1) JSONL ìš°ì„ : ./, outputs/, logs/ ìˆœìœ¼ë¡œ íƒìƒ‰
used_path: Optional[Path] = None
jl_path = _find_file(session_dir, "trades.jsonl")
rows = _read_jsonl(jl_path, limit=max_rows) if jl_path else []
df = pd.DataFrame(rows)
if not df.empty:
    used_path = jl_path

# 2) ë¹„ì–´ìˆìœ¼ë©´ CSV í´ë°±
if df.empty:
    csv_path = _find_file(session_dir, "trades.csv")
    if csv_path:
        try:
            df = pd.read_csv(csv_path)
            used_path = csv_path
        except (OSError, UnicodeDecodeError, ValueError, pd.errors.ParserError):
            df = pd.DataFrame()

if df.empty:
    st.info("í‘œì‹œí•  ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤. (trades.jsonl/csv ë¯¸ì¡´ì¬ ë˜ëŠ” ë¹„ì–´ìˆìŒ)")
    st.stop()

# í‘œì¤€ ì»¬ëŸ¼ ì •ë¦¬
df["ts"] = df.apply(lambda r: _coalesce(r.get("ts"), r.get("ts_utc"), r.get("time")), axis=1)
df["ts_local"] = df["ts"].map(lambda s: _to_local_ts(s) if isinstance(s, str) else s)
for col in ("qty", "price", "commission"):
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="coerce")
if "qty" in df.columns and "price" in df.columns:
    df["notional"] = df["qty"].fillna(0) * df["price"].fillna(0)

# KPI
total_trades = len(df)
if "side" in df.columns:
    buys = int((df["side"] == "buy").sum())
    sells = int((df["side"] == "sell").sum())
elif "reason" in df.columns:
    # reason í…ìŠ¤íŠ¸ì—ì„œ buy/sell í‚¤ì›Œë“œ ì¶”ì •
    _reason = df["reason"].astype(str)
    buys = int(_reason.str.contains("buy", case=False, na=False).sum())
    sells = int(_reason.str.contains("sell", case=False, na=False).sum())
else:
    buys = sells = 0

notional_sum = float(pd.to_numeric(df.get("notional", pd.Series(dtype=float)), errors="coerce").fillna(0).sum())
commission_sum = float(pd.to_numeric(df.get("commission", pd.Series(dtype=float)), errors="coerce").fillna(0).sum())

c1, c2, c3, c4 = st.columns(4)
c1.metric("ì´ ê±°ë˜ìˆ˜", f"{total_trades:,}")
c2.metric("ë§¤ìˆ˜/ë§¤ë„", f"{buys:,} / {sells:,}")
c3.metric("ì´ ì²´ê²° ê¸ˆì•¡(ì ˆëŒ€)", f"{notional_sum:,.2f}")
c4.metric("ìˆ˜ìˆ˜ë£Œ í•©ê³„", f"{commission_sum:,.4f}")

st.divider()

# í•„í„°
with st.expander("ğŸ” í•„í„°"):
    symbols = sorted(df.get("symbol", pd.Series(dtype=str)).dropna().unique().tolist())
    sides = sorted(df.get("side", pd.Series(dtype=str)).dropna().unique().tolist())
    reasons = sorted(df.get("reason", pd.Series(dtype=str)).dropna().unique().tolist())

    sel_symbols = st.multiselect("ì‹¬ë³¼", symbols, default=[])
    sel_sides = st.multiselect("ì‚¬ì´ë“œ", sides, default=[])
    sel_reasons = st.multiselect("ì‚¬ìœ ", reasons, default=[])

    if sel_symbols:
        df = df[df["symbol"].isin(sel_symbols)]
    if sel_sides and "side" in df:
        df = df[df["side"].isin(sel_sides)]
    if sel_reasons and "reason" in df:
        df = df[df["reason"].isin(sel_reasons)]

# ì •ë ¬: ìµœì‹ ìˆœ
if "ts" in df.columns:
    try:
        df["_ts_sort"] = pd.to_datetime(df["ts"], utc=True, errors="coerce")
        df = df.sort_values("_ts_sort", ascending=False).drop(columns=["_ts_sort"])
    except Exception:
        df = df.sort_values("ts", ascending=False)

show_cols = [
    c
    for c in [
        "ts_local",
        "ts",
        "symbol",
        "side",
        "qty",
        "price",
        "notional",
        "commission",
        "reason",
        "broker",
        "tif",
        "order_id",
    ]
    if c in df.columns
]

st.subheader("ì‹¤ì‹œê°„ ë§¤ë§¤ ë¡œê·¸")
st.dataframe(df[show_cols].head(max_rows), use_container_width=True)

st.caption(f"ì„¸ì…˜: {sel_session} Â· ê²½ë¡œ: {used_path if used_path else 'N/A'} Â· {len(df)}í–‰ ì¤‘ ìƒìœ„ {min(max_rows, len(df))}í–‰ í‘œì‹œ")
